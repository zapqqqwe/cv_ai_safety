{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "\n",
    "# 下载CIFAR-10数据集\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 提取特征和标签\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for data in trainset:\n",
    "    image, label = data\n",
    "    # 将图像数据展平为特征向量\n",
    "    feature_vector = image.view(-1).numpy()\n",
    "    X_train.append(feature_vector)\n",
    "    y_train.append(label)\n",
    "\n",
    "for data in testset:\n",
    "    image, label = data\n",
    "    feature_vector = image.view(-1).numpy()\n",
    "    X_test.append(feature_vector)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 定义SVM训练函数\n",
    "def train_linear_svm(X, y, learning_rate=0.01, num_epochs=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        for i, x in enumerate(X):\n",
    "            condition = y[i] * (np.dot(x, weights) - bias) >= 1\n",
    "            if condition:\n",
    "                weights -= learning_rate * (2 / epoch * weights)\n",
    "            else:\n",
    "                weights -= learning_rate * (2 / epoch * weights - x * y[i])\n",
    "                bias -= learning_rate * y[i]\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# 训练SVM\n",
    "weights, bias = train_linear_svm(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "def predict(X, weights, bias):\n",
    "    return np.sign(np.dot(X, weights) - bias)\n",
    "\n",
    "y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "# 评估性能\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "accuracy_value = accuracy(y_test, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy_value * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SVM(object):\n",
    "    def __init__(self):\n",
    "        # W为加上偏置的权重（D,num_class)\n",
    "        self.W = None\n",
    "    def svm_loss_naive(self, x, y, reg):\n",
    "        \"\"\"\n",
    "        功能：非矢量化版本的损失函数\n",
    "        输入：\n",
    "        -x：(numpy array)样本数据（N,D)\n",
    "        -y：(numpy array)标签（N，）\n",
    "        -reg：(float)正则化强度\n",
    "        输出：\n",
    "        (float)损失函数值loss\n",
    "        (numpy array)权重梯度dW\n",
    "        \"\"\"\n",
    "        num_train = x.shape[0]\n",
    "        num_class = self.W.shape[1]\n",
    "        # 初始化\n",
    "        loss = 0.0\n",
    "        dW = np.zeros(self.W.shape)\n",
    "        for i in range(num_train):\n",
    "            scores = x[i].dot(self.W)\n",
    "            # 计算边界,delta=1\n",
    "            margin = scores - scores[y[i]] + 1\n",
    "            # 把正确类别的归0\n",
    "            margin[y[i]] = 0\n",
    "            for j in range(num_class):\n",
    "                # max操作\n",
    "                if j == y[i]:\n",
    "                    continue\n",
    "                if margin[j] > 0:\n",
    "                    loss += margin[j]\n",
    "                    dW[:, y[i]] += -x[i]\n",
    "                    dW[:, j] += x[i]\n",
    "        # 要除以N\n",
    "        loss /= num_train\n",
    "        dW /= num_train\n",
    "        # 加上正则项\n",
    "        loss += 0.5 * reg * np.sum(self.W * self.W)\n",
    "        dW += reg * self.W\n",
    "        return loss, dW\n",
    "    def svm_loss_vectorized(self, x, y, reg):\n",
    "        \"\"\"\n",
    "        功能：矢量化版本的损失函数\n",
    "        输入：\n",
    "        -x：(numpy array)样本数据（N,D)\n",
    "        -y：(numpy array)标签（N，）\n",
    "        -reg：(float)正则化强度\n",
    "        输出：\n",
    "        (float)损失函数值loss\n",
    "        (numpy array)权重梯度dW\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        dW = np.zeros(self.W.shape)\n",
    "        num_train = x.shape[0]\n",
    "        scores = x.dot(self.W)\n",
    "        margin = scores - scores[np.arange(num_train), y].reshape(num_train, 1) + 1\n",
    "        margin[np.arange(num_train), y] = 0.0\n",
    "        # max操作\n",
    "        margin = (margin > 0) * margin\n",
    "        loss += margin.sum() / num_train\n",
    "        # 加上正则化项\n",
    "        loss += 0.5 * reg * np.sum(self.W * self.W)\n",
    "        # 计算梯度\n",
    "        margin = (margin > 0) * 1\n",
    "        row_sum = np.sum(margin, axis=1)\n",
    "        margin[np.arange(num_train), y] = -row_sum\n",
    "        dW = x.T.dot(margin) / num_train + reg * self.W\n",
    "        return loss, dW\n",
    "    def train(self, x, y, reg=1e-5, learning_rate=1e-3, num_iters=100, batch_size=200, verbose=False):\n",
    "        \"\"\"\n",
    "        功能：使用随机梯度下降法训练SVM\n",
    "        输入：\n",
    "        -x:(numpy array)训练样本（N,D）\n",
    "        -y:(numpy array)训练样本标签(N,)\n",
    "        -reg:(float)正则化强度\n",
    "        -learning_rate:(float)进行权重更新的学习率\n",
    "        -num_iters:(int)优化的迭代次数\n",
    "        -batch_size:(int)随机梯度下降法每次使用的梯度大小\n",
    "        -verbose:(bool)取True时，打印输出loss的变化过程\n",
    "        输出：-history_loss:(list)存储每次迭代后的loss值\n",
    "        \"\"\"\n",
    "        num_train, dim = x.shape\n",
    "        num_class = np.max(y) + 1\n",
    "        # 初始化权重\n",
    "        if self.W is None:\n",
    "            self.W = 0.005 * np.random.randn(dim, num_class)\n",
    "        batch_x = None\n",
    "        batch_y = None\n",
    "        history_loss = []\n",
    "        # 随机梯度下降法优化权重\n",
    "        for i in range(num_iters):\n",
    "            # 从训练样本中随机取样作为更新权重的小批量样本\n",
    "            mask = np.random.choice(num_train, batch_size, replace=False)\n",
    "            batch_x = x[mask]\n",
    "            batch_y = y[mask]\n",
    "            # 计算loss和权重的梯度\n",
    "            loss, grad = self.svm_loss_vectorized(batch_x, batch_y, reg)\n",
    "            # 更新权重\n",
    "            self.W += -learning_rate * grad\n",
    "            history_loss.append(loss)\n",
    "            # 打印loss的变化过程\n",
    "            if verbose == True and i % 100 == 0:\n",
    "                print(\"iteratons:%d/%d,loss:%f\" % (i, num_iters, loss))\n",
    "        return history_loss\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        功能：利用训练得到的最优权值预测分类结果\n",
    "        输入：\n",
    "        -x:(numpy array)待分类的样本(N,D)\n",
    "        输出：y_pre(numpy array)预测的便签(N,)\n",
    "        \"\"\"\n",
    "        y_pre = np.zeros(x.shape[0])\n",
    "        scores = x.dot(self.W)\n",
    "        y_pre = np.argmax(scores, axis=1)\n",
    "        return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "iteratons:0/1000,loss:9.047402\n",
      "iteratons:100/1000,loss:6.713098\n",
      "iteratons:200/1000,loss:5.686685\n",
      "iteratons:300/1000,loss:4.990122\n",
      "iteratons:400/1000,loss:4.877725\n",
      "iteratons:500/1000,loss:5.542544\n",
      "iteratons:600/1000,loss:5.016349\n",
      "iteratons:700/1000,loss:4.971366\n",
      "iteratons:800/1000,loss:4.948975\n",
      "iteratons:900/1000,loss:4.541818\n",
      "Accuracy on the test set: 34.66%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "\n",
    "# 下载CIFAR-10数据集\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 提取特征和标签\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for data in trainset:\n",
    "    image, label = data\n",
    "    feature_vector = image.view(-1).numpy()\n",
    "    X.append(feature_vector)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化SVM模型\n",
    "svm = SVM()\n",
    "\n",
    "# 训练SVM模型\n",
    "history_loss = svm.train(X_train, y_train, reg=1e-5, learning_rate=1e-3, num_iters=1000, batch_size=200, verbose=True)\n",
    "\n",
    "# 预测\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# 评估性能\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 34.66%\n",
      "Precision on the test set: 37.21%\n",
      "Recall on the test set: 34.73%\n",
      "F1 Score on the test set: 33.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.50      0.39       973\n",
      "           1       0.41      0.36      0.39       979\n",
      "           2       0.36      0.10      0.16      1030\n",
      "           3       0.36      0.09      0.14      1023\n",
      "           4       0.31      0.32      0.31       933\n",
      "           5       0.23      0.55      0.33      1015\n",
      "           6       0.37      0.43      0.40       996\n",
      "           7       0.46      0.27      0.34       994\n",
      "           8       0.48      0.38      0.42      1017\n",
      "           9       0.43      0.47      0.45      1040\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.37      0.35      0.33     10000\n",
      "weighted avg       0.37      0.35      0.33     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print(f'Precision on the test set: {precision * 100:.2f}%')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(f'Recall on the test set: {recall * 100:.2f}%')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'F1 Score on the test set: {f1 * 100:.2f}%')\n",
    "\n",
    "# 输出详细的分类报告\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
